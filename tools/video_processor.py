"""
ë¹„ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ ë„êµ¬
ë™ì˜ìƒì„ í”„ë ˆì„ìœ¼ë¡œ ë¶„í• í•˜ê³  YOLO í˜•ì‹ ë°ì´í„°ì…‹ì„ ìƒì„±
"""
import os
import cv2
import glob
import shutil
from pathlib import Path
import argparse


def extract_frames_from_video(video_path, output_dir, frame_interval=1):
    """
    ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ ì´ë¯¸ì§€ë¡œ ì €ì¥
    
    Args:
        video_path (str): ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        output_dir (str): í”„ë ˆì„ ì €ì¥ ë””ë ‰í† ë¦¬
        frame_interval (int): í”„ë ˆì„ ì¶”ì¶œ ê°„ê²© (1 = ëª¨ë“  í”„ë ˆì„)
    """
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print(f"Error: Could not open video {video_path}")
        return False
    
    frame_count = 0
    saved_count = 0
    
    # ë¹„ë””ì˜¤ ì´ë¦„ìœ¼ë¡œ ë””ë ‰í† ë¦¬ ìƒì„±
    video_name = Path(video_path).stem
    video_output_dir = os.path.join(output_dir, video_name)
    os.makedirs(video_output_dir, exist_ok=True)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        if frame_count % frame_interval == 0:
            # í”„ë ˆì„ì„ ì´ë¯¸ì§€ë¡œ ì €ì¥
            frame_filename = f"frame_{saved_count:06d}.jpg"
            frame_path = os.path.join(video_output_dir, frame_filename)
            cv2.imwrite(frame_path, frame)
            saved_count += 1
            
        frame_count += 1
    
    cap.release()
    print(f"Extracted {saved_count} frames from {video_path}")
    return True


def process_videos_to_frames(video_dir, output_dir, frame_interval=1):
    """
    ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    
    Args:
        video_dir (str): ë¹„ë””ì˜¤ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_dir (str): í”„ë ˆì„ ì €ì¥ ë””ë ‰í† ë¦¬
        frame_interval (int): í”„ë ˆì„ ì¶”ì¶œ ê°„ê²©
    """
    # ì§€ì›í•˜ëŠ” ë¹„ë””ì˜¤ í¬ë§·
    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv', '*.flv']
    
    video_files = []
    for ext in video_extensions:
        video_files.extend(glob.glob(os.path.join(video_dir, ext)))
        video_files.extend(glob.glob(os.path.join(video_dir, ext.upper())))
    
    if not video_files:
        print(f"No video files found in {video_dir}")
        return
    
    print(f"Found {len(video_files)} video files")
    
    os.makedirs(output_dir, exist_ok=True)
    
    for video_path in video_files:
        print(f"Processing: {os.path.basename(video_path)}")
        extract_frames_from_video(video_path, output_dir, frame_interval)


def create_yolo_dataset_structure(frames_dir, output_dir):
    """
    í”„ë ˆì„ë“¤ì„ YOLO ë°ì´í„°ì…‹ êµ¬ì¡°ë¡œ ì •ë¦¬
    
    Args:
        frames_dir (str): í”„ë ˆì„ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_dir (str): YOLO ë°ì´í„°ì…‹ ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    # YOLO ë°ì´í„°ì…‹ êµ¬ì¡° ìƒì„±
    train_img_dir = os.path.join(output_dir, 'train', 'images')
    train_label_dir = os.path.join(output_dir, 'train', 'labels')
    val_img_dir = os.path.join(output_dir, 'val', 'images')
    val_label_dir = os.path.join(output_dir, 'val', 'labels')
    test_img_dir = os.path.join(output_dir, 'test', 'images')
    test_label_dir = os.path.join(output_dir, 'test', 'labels')
    
    for dir_path in [train_img_dir, train_label_dir, val_img_dir, val_label_dir, 
                     test_img_dir, test_label_dir]:
        os.makedirs(dir_path, exist_ok=True)
    
    # ëª¨ë“  í”„ë ˆì„ íŒŒì¼ ìˆ˜ì§‘
    frame_files = []
    for video_dir in os.listdir(frames_dir):
        video_path = os.path.join(frames_dir, video_dir)
        if os.path.isdir(video_path):
            for frame_file in os.listdir(video_path):
                if frame_file.endswith('.jpg'):
                    frame_files.append(os.path.join(video_path, frame_file))
    
    frame_files.sort()
    
    # ë°ì´í„° ë¶„í•  (80% train, 10% val, 10% test)
    total_frames = len(frame_files)
    train_end = int(total_frames * 0.8)
    val_end = int(total_frames * 0.9)
    
    train_frames = frame_files[:train_end]
    val_frames = frame_files[train_end:val_end]
    test_frames = frame_files[val_end:]
    
    # í”„ë ˆì„ ë³µì‚¬
    for i, frame_path in enumerate(train_frames):
        filename = f"train_{i:06d}.jpg"
        shutil.copy2(frame_path, os.path.join(train_img_dir, filename))
    
    for i, frame_path in enumerate(val_frames):
        filename = f"val_{i:06d}.jpg"
        shutil.copy2(frame_path, os.path.join(val_img_dir, filename))
    
    for i, frame_path in enumerate(test_frames):
        filename = f"test_{i:06d}.jpg"
        shutil.copy2(frame_path, os.path.join(test_img_dir, filename))
    
    print(f"Dataset created:")
    print(f"  Train: {len(train_frames)} frames")
    print(f"  Val: {len(val_frames)} frames")
    print(f"  Test: {len(test_frames)} frames")


def main():
    parser = argparse.ArgumentParser(description='Process videos to YOLO dataset')
    parser.add_argument('--video_dir', type=str, default='data/videos',
                       help='Directory containing video files')
    parser.add_argument('--frames_dir', type=str, default='data/frames',
                       help='Directory to save extracted frames')
    parser.add_argument('--dataset_dir', type=str, default='data',
                       help='Directory to save YOLO dataset')
    parser.add_argument('--frame_interval', type=int, default=1,
                       help='Frame extraction interval (1 = every frame)')
    
    args = parser.parse_args()
    
    print("ğŸ¥ Video Processing Pipeline")
    print("=" * 50)
    
    # 1ë‹¨ê³„: ë¹„ë””ì˜¤ë¥¼ í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    print("Step 1: Extracting frames from videos...")
    process_videos_to_frames(args.video_dir, args.frames_dir, args.frame_interval)
    
    # 2ë‹¨ê³„: YOLO ë°ì´í„°ì…‹ êµ¬ì¡° ìƒì„±
    print("\nStep 2: Creating YOLO dataset structure...")
    create_yolo_dataset_structure(args.frames_dir, args.dataset_dir)
    
    print("\nâœ… Video processing completed!")
    print(f"Dataset saved to: {args.dataset_dir}")


if __name__ == "__main__":
    main()

